{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step one\n",
    "### Data Engineering Pipeline - Extract, Transform, Load (ETL) 3. Data integration (extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract\n",
    "Data is coming in multiple formats:\n",
    "\n",
    "1. `csv` files: ['ids_0.csv', 'ids_1.csv', 'ids_2.csv']\n",
    "2. `json` files: ['ids_3.json', 'ids_4.json', 'ids_7.json', 'ids_9.json', 'ids_10.json']\n",
    "3. `parquet` files: ['ids_5.parquet', 'ids_6.parquet', 'ids_8.parquet', 'ids_11.parquet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    \"\"\"This function combines all the csv, json, and parquet files into a dataframe\n",
    "    \n",
    "    Args:\n",
    "        None: The function reads all csv and json finles in the working directory\n",
    "        \n",
    "    Returns: \n",
    "        data (pd.dataframe): All data sources combined in a single dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    #Create an empty dataframe to hold all the data.\n",
    "    #Column names remain as they were int the original files.\n",
    "    data = pd.DataFrame(columns=[' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
    "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
    "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
    "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
    "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
    "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
    "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
    "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
    "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
    "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
    "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
    "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
    "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
    "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
    "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
    "       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n",
    "       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n",
    "       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
    "       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n",
    "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
    "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
    "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n",
    "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
    "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
    "       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n",
    "       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min',\n",
    "       ' Label'])\n",
    "    \n",
    "    #For each file type: Create a temporary dataframe and concatenate to the 'data' dataframe.\n",
    "    for csvfile in glob.glob('*.csv'):\n",
    "        tmp_df = pd.read_csv(csvfile)\n",
    "        data = pd.concat([data,tmp_df], ignore_index=True)\n",
    "\n",
    "    for jsonfile in glob.glob('*.json'):\n",
    "        tmp_df = pd.read_json(jsonfile,lines=True)\n",
    "        data = pd.concat([data, tmp_df], ignore_index=True)\n",
    "\n",
    "    for parquetfile in glob.glob('*.parquet'):\n",
    "        tmp_df = pd.read_parquet(parquetfile)\n",
    "        data = pd.concat([data,tmp_df], ignore_index=True)\n",
    "    \n",
    "    #Return combined data.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis A. Torres\\AppData\\Local\\Temp\\ipykernel_20524\\1002071927.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data,tmp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (61128, 141)\n",
      "column names: Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
      "       'Total Backward Packets', 'Total Length of Fwd Packets',\n",
      "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
      "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std',\n",
      "       ...\n",
      "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
      "       ' min_seg_size_forward', ' Active Std', ' Active Max', ' Active Min',\n",
      "       ' Idle Std', ' Idle Max', ' Idle Min', ' Label'],\n",
      "      dtype='object', length=141)\n"
     ]
    }
   ],
   "source": [
    "data = extract()\n",
    "print('data shape:', data.shape)\n",
    "print('column names:', data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ids_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the CSV files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m csv0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(ids_0\u001b[38;5;241m.\u001b[39mcsv)\n\u001b[0;32m      3\u001b[0m csv1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(ids_1\u001b[38;5;241m.\u001b[39mcsv)\n\u001b[0;32m      4\u001b[0m csv2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(ids_2\u001b[38;5;241m.\u001b[39mcsv)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ids_0' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "csv0 = pd.read_csv(\"ids_0.csv\")\n",
    "csv1 = pd.read_csv(\"ids_1.csv\")\n",
    "csv2 = pd.read_csv(\"ids_2.csv\")\n",
    "combined = pd.concat([ csv0 , csv1 , csv2], ignore_index=True)\n",
    "\n",
    "# Load the JSON files\n",
    "json3 = pd.read_json(\"ids_3.json\", lines=True)\n",
    "json4 = pd.read_json(\"ids_4.json\", lines=True)\n",
    "json7 = pd.read_json(\"ids_7.json\", lines=True)\n",
    "json9 = pd.read_json(\"ids_9.json\", lines=True)\n",
    "json10 = pd.read_json(\"ids_10.json\", lines=True)\n",
    "combined = pd.concat([combined , json3 , json4 , json7 , json9 , json10], ignore_index=True)\n",
    "\n",
    "# Load the Parquet files\n",
    "parquet5 = pd.read_parquet(\"ids_5.parquet\")\n",
    "parquet6 = pd.read_parquet(\"ids_6.parquet\")\n",
    "parquet8 = pd.read_parquet(\"ids_8.parquet\")\n",
    "parquet11 = pd.read_parquet(\"ids_11.parquet\")\n",
    "combined = pd.concat([combined , parquet5 , parquet6 , parquet8 , parquet11], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
